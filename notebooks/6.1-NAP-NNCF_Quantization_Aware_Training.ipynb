{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a2c8b27-93c2-444e-9b12-52a6a9d40595",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['TF_ENABLE_ONEDNN_OPTS'] = '1'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c54b1823-fb26-496c-bf58-d3c6b59b927e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import logging\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras as K\n",
    "#from tensorflow.python.keras import layers\n",
    "#from tensorflow.python.keras import models\n",
    "\n",
    "import nibabel as nib\n",
    "import numpy as np\n",
    "import os\n",
    "import datetime\n",
    "    \n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from nncf import NNCFConfig\n",
    "from nncf.tensorflow.helpers.model_creation import create_compressed_model\n",
    "from nncf.tensorflow.initialization import register_default_init_args\n",
    "from nncf.common.utils.logger import set_log_level\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49bbd2d7-4551-4b71-8be6-c8aebcf713ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "Need to define a data path, original model path, and all created model paths\n",
    "\n",
    "tensorflow model in fp32 (h5 & pb)\n",
    "\n",
    "tensorflow + mo in various data types\n",
    "\n",
    "tensorflow + pot in various data types\n",
    "\n",
    "tensorflow + nncf \n",
    "\n",
    "tensorflow + nncf + mo in various datatypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43cbef0b-db88-4f0b-8982-50986d53398c",
   "metadata": {},
   "outputs": [],
   "source": [
    "models\n",
    "    base_model_name + framework + datatype\n",
    "    base_model_name + framework + openvino + datatype\n",
    "    base_model_name + framework + openvino + pot + datatype\n",
    "    base_model_name + framework + nncf + datatype\n",
    "    base_model_name + framework + nncf + openvino + datatype\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80222c36-7499-43c3-b518-bd8d0726c3b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "set_log_level(logging.ERROR)\n",
    "\n",
    "MODEL_DIR = Path(\"/home/ubuntu/unet/3D/models\")\n",
    "OUTPUT_DIR = Path(\"/home/ubuntu/unet/3D/models/openvino\")\n",
    "\n",
    "\n",
    "MODEL_DIR.mkdir(parents=True, exist_ok=True)\n",
    "OUTPUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "BASE_MODEL_NAME = \"3d_unet_decathlon\"\n",
    "\n",
    "\n",
    "# Path of baseline TF model with FP32 precision\n",
    "fp32_h5_path = Path(MODEL_DIR / BASE_MODEL_NAME / BASE_MODEL_NAME).with_suffix(\".h5\")\n",
    "fp32_sm_path = Path(MODEL_DIR / BASE_MODEL_NAME / \"saved_model.pb\")\n",
    "\n",
    "# Path of optimized TF model using OpenVINO Model Optimizer with FP32 precision\n",
    "fp32_ir_name = Path(BASE_MODEL_NAME + \"_\" + \"tf\" + \"_\" + \"ov\" + \"_\" + \"fp32\" + \"_ir\").with_suffix(\".xml\")\n",
    "fp32_ir_path = Path(OUTPUT_DIR / fp32_ir_name)\n",
    "\n",
    "# Path of compressed TF model using OpenVINO Neural Net Compression Framework with INT8 precision\n",
    "int8_pb_folder = Path(BASE_MODEL_NAME + \"_\" + \"tf\" + \"_\" + \"nncf\" + \"_\" + \"int8\")#.with_suffix(\".pb\")\n",
    "int8_pb_path = Path(OUTPUT_DIR / int8_pb_folder)\n",
    "int8_pb_path.mkdir(parents=True, exist_ok=True)\n",
    "int8_pb_file = Path(int8_pb_path / \"saved_model\").with_suffix(\".pb\")\n",
    "\n",
    "\n",
    "# Path of finetuned, compressed TF model using OpenVINO Neural Net Compression Framework with INT8 precision\n",
    "int8_ft_pb_folder = Path(BASE_MODEL_NAME + \"_\" + \"tf\" + \"_\" + \"nncf\" + \"_\" + \"ft_\"+ \"int8\")#.with_suffix(\".pb\")\n",
    "int8_ft_pb_path = Path(OUTPUT_DIR / int8_ft_pb_folder)\n",
    "int8_ft_pb_path.mkdir(parents=True, exist_ok=True)\n",
    "int8_ft_pb_file = Path(int8_ft_pb_path / \"saved_model\").with_suffix(\".pb\")\n",
    "\n",
    "# # Path of finetuned, compressed TF model using OpenVINO Neural Net Compression Framework with INT8 precision\n",
    "# int8_ft_pb_name = Path(BASE_MODEL_NAME + \"_\" + \"tf\" + \"_\" + \"nncf\" + \"_\" + \"ft_\"+ \"int8\").with_suffix(\".pb\")\n",
    "# int8_ft_pb_path = Path(OUTPUT_DIR / int8_ft_pb_name)\n",
    "\n",
    "\n",
    "# Path of optimized, compressed TF model using OpenVINO Neural Net Compression Framework then Model Optimizer with INT8 precision\n",
    "int8_ir_name = Path(BASE_MODEL_NAME + \"_\" + \"tf\" + \"_\" + \"nncf\" + \"_\" + \"ov\" + \"_\" + \"int8\" + \"_ir\").with_suffix(\".xml\")\n",
    "int8_ir_path = Path(OUTPUT_DIR / int8_ir_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50a01ada-4d5a-499c-81e2-58ebe430d58d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path=\"/home/ubuntu/unet/data/Task01_BrainTumour/\"\n",
    "train_test_split = 0.80\n",
    "validate_test_split = 0.50\n",
    "batch_size_train = 8\n",
    "batch_size_validate = 4\n",
    "batch_size_test = 1\n",
    "crop_dim = (128,128,128,1)\n",
    "#crop_dim = (144,144,144,1)\n",
    "\n",
    "tile_height = 128\n",
    "tile_width = 128\n",
    "tile_depth = 128\n",
    "number_input_channels = 1\n",
    "\n",
    "number_output_classes = 1\n",
    "random_seed = 64\n",
    "\n",
    "filters = 8\n",
    "#saved_model_name = \"3d_unet_decathlon\"\n",
    "\n",
    "\n",
    "num_epochs=30\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8692b515-0290-45f4-99f2-aab10f9ab51a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mkl_enabled_flag():\n",
    "\n",
    "    mkl_enabled = False\n",
    "    major_version = int(tf.__version__.split(\".\")[0])\n",
    "    minor_version = int(tf.__version__.split(\".\")[1])\n",
    "    if major_version >= 2:\n",
    "        if minor_version < 5:\n",
    "            from tensorflow.python import _pywrap_util_port\n",
    "        elif minor_version >= 9:\n",
    "\n",
    "            from tensorflow.python.util import _pywrap_util_port\n",
    "            onednn_enabled = int(os.environ.get('TF_ENABLE_ONEDNN_OPTS', '1'))\n",
    "\n",
    "        else:\n",
    "            from tensorflow.python.util import _pywrap_util_port\n",
    "            onednn_enabled = int(os.environ.get('TF_ENABLE_ONEDNN_OPTS', '0'))\n",
    "        mkl_enabled = _pywrap_util_port.IsMklEnabled() or (onednn_enabled == 1)\n",
    "    else:\n",
    "        mkl_enabled = tf.pywrap_tensorflow.IsMklEnabled()\n",
    "    return mkl_enabled\n",
    "\n",
    "print (\"We are using Tensorflow version\", tf.__version__)\n",
    "print(\"MKL enabled :\", get_mkl_enabled_flag())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94b301e5-8cf9-4bc0-9d8e-aaa089058320",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataloader import DatasetGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea800f5a-e209-4197-970a-0836b8217184",
   "metadata": {},
   "outputs": [],
   "source": [
    "brats_datafiles = DatasetGenerator(data_path=data_path, \n",
    "                                   train_test_split=train_test_split,\n",
    "                                   validate_test_split=validate_test_split,\n",
    "                                   batch_size_train=batch_size_train,\n",
    "                                   batch_size_validate=batch_size_validate,\n",
    "                                   batch_size_test=batch_size_test,\n",
    "                                   tile_height=tile_height, \n",
    "                                   tile_width=tile_width, \n",
    "                                   tile_depth=tile_depth, \n",
    "                                   number_input_channels=number_input_channels,\n",
    "                                   number_output_classes=number_output_classes,\n",
    "                                   random_seed=random_seed)\n",
    "brats_datafiles.print_info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5b847bc-40d1-4354-9fe4-d3938f90a463",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and complie the baseline TF model with FP32 precision\n",
    "from model import dice_coef, soft_dice_coef, dice_loss\n",
    "tf_baseline_model_fp32 = tf.keras.models.load_model(fp32_h5_path, \n",
    "                                      compile=False, \n",
    "                                      custom_objects={\"dice_coef\":dice_coef, \"soft_dice_coef\":soft_dice_coef, \"dice_loss\":dice_loss})\n",
    "tf_baseline_model_fp32.compile(loss=dice_loss, optimizer=\"adam\", metrics=[dice_coef, soft_dice_coef])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa630182-20ef-4b8c-ad0e-8ba239738780",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validate the model\n",
    "tf_baseline_fp32_loss, tf_baseline_fp32_dice_coef, tf_baseline_fp32_soft_dice_coef = tf_baseline_model_fp32.evaluate(brats_datafiles.get_test())\n",
    "print(f\"\\nLoss of TF Baseline FP32 model: {tf_baseline_fp32_loss:.3f}\\nDice Coef of FP32 model: {tf_baseline_fp32_dice_coef:.3f}\\nSoft Dice Coef of FP32 model: {tf_baseline_fp32_soft_dice_coef:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6b44454-8fdf-4359-9901-deb5b74c0d0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "nncf_config_dict = {\n",
    "    \"input_info\": {\"sample_size\": [1, number_input_channels, tile_height, tile_width, tile_depth]},\n",
    "    \"log_dir\": str(OUTPUT_DIR),  # The log directory for NNCF-specific logging outputs.\n",
    "    \"compression\": {\n",
    "        \"algorithm\": \"quantization\",  # Specify the algorithm here.\n",
    "    },\n",
    "}\n",
    "nncf_config = NNCFConfig.from_dict(nncf_config_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7428db3-b05e-4e1b-b8d4-73da301a8b8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "nncf_config = register_default_init_args(nncf_config=nncf_config,\n",
    "                                         data_loader=brats_datafiles.get_train(),\n",
    "                                         batch_size=batch_size_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6802b72-81f1-4956-a739-287d6ac2d92a",
   "metadata": {},
   "outputs": [],
   "source": [
    "compression_ctrl, compressed_tf_model_int8 = create_compressed_model(tf_baseline_model_fp32, nncf_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d844817-2645-4da8-9dcf-8695b8ae8e8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "compression_ctrl.export_model(int8_pb_file, 'frozen_graph')\n",
    "print(f'Absolute path where the int8 model is saved:\\n {int8_pb_file.resolve()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0390b83b-d171-4801-a41a-4256a297a4c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_nncf = tf.keras.models.load_model(int8_pb_path, \n",
    "                                      compile=False, \n",
    "                                      custom_objects={\"dice_coef\":dice_coef, \"soft_dice_coef\":soft_dice_coef, \"dice_loss\":dice_loss})\n",
    "test_nncf.compile(loss=dice_loss, optimizer=\"adam\", metrics=[dice_coef, soft_dice_coef])\n",
    "\n",
    "# Validate the INT8 model.\n",
    "test_nncf_loss, test_nncf_dice_coef, test_nncf_soft_dice_coef = test_nncf.evaluate(brats_datafiles.get_test())\n",
    "print(f\"\\nLoss of test_nncf INT8 model: {test_nncf_loss:.3f}\\nDice Coef of test_nncf INT8 model: {test_nncf_dice_coef:.3f}\\nSoft Dice Coef of test_nncf INT8 model: {test_nncf_soft_dice_coef:.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eee3b9f0-67b7-44bd-b034-d6d61c54ce46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the INT8 model.\n",
    "compressed_tf_model_int8.compile(optimizer=\"adam\", \n",
    "              loss=dice_loss,\n",
    "              metrics=[dice_coef, soft_dice_coef])\n",
    "\n",
    "# Validate the INT8 model.\n",
    "compressed_tf_model_int8_loss, compressed_tf_model_int8_dice_coef, compressed_tf_model_int8_soft_dice_coef = compressed_tf_model_int8.evaluate(brats_datafiles.get_test())\n",
    "print(f\"\\nLoss of INT8 model: {compressed_tf_model_int8_loss:.3f}\\nDice Coef of INT8 model: {compressed_tf_model_int8_dice_coef:.3f}\\nSoft Dice Coef of INT8 model: {compressed_tf_model_int8_soft_dice_coef:.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6e49176-fdd4-4d02-b6e0-39137531a683",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the INT8 model.\n",
    "steps_per_epoch = brats_datafiles.num_train // batch_size_train\n",
    "\n",
    "compressed_tf_model_int8.fit(brats_datafiles.get_train(),\n",
    "          steps_per_epoch=steps_per_epoch,\n",
    "          epochs=2)\n",
    "\n",
    "# Validate the INT8 model.\n",
    "compressed_ft_tf_model_int8_loss, compressed_ft_tf_model_int8_dice_coef, compressed_ft_tf_model_int8_soft_dice_coef  = compressed_tf_model_int8.evaluate(brats_datafiles.get_test())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "054e15a0-f404-4c1d-ad92-a4cf9161a8c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(f\"\\nAccuracy drop of tuned INT8 model over pre-trained FP32 model: {acc_fp32 - acc_int8:.3f}\")\n",
    "print(f\"Loss of FP32 model: {tf_baseline_fp32_loss:.3f}\\nDice Coef of FP32 model: {tf_baseline_fp32_dice_coef:.3f}\\nSoft Dice Coef of FP32 model: {tf_baseline_fp32_soft_dice_coef:.3f}\")\n",
    "print(f\"\\nLoss of INT8 model: {compressed_tf_model_int8_loss:.3f}\\nDice Coef of INT8 model: {compressed_tf_model_int8_dice_coef:.3f}\\nSoft Dice Coef of INT8 model: {compressed_tf_model_int8_soft_dice_coef:.3f}\")\n",
    "print(f\"\\nLoss of Finetuned INT8 model: {compressed_ft_tf_model_int8_loss:.3f}\\nDice Coef of Finetuned INT8 model: {compressed_ft_tf_model_int8_dice_coef:.3f}\\nSoft Dice Coef of Finetuned INT8 model: {compressed_ft_tf_model_int8_soft_dice_coef:.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b13d9ee9-a496-4dd3-a552-aad44dc45758",
   "metadata": {},
   "outputs": [],
   "source": [
    "compressed_tf_model_int8.save(int8_ft_pb_path)\n",
    "print(f'Absolute path where the model is saved:\\n {int8_ft_pb_path.resolve()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfe5c6db-9d2c-4b4b-b991-6b186444a614",
   "metadata": {},
   "outputs": [],
   "source": [
    "from model import dice_coef, soft_dice_coef, dice_loss\n",
    "\n",
    "test_nncf_ft = tf.keras.models.load_model(int8_ft_pb_path, \n",
    "                                      compile=False, \n",
    "                                      custom_objects={\"dice_coef\":dice_coef, \"soft_dice_coef\":soft_dice_coef, \"dice_loss\":dice_loss})\n",
    "test_nncf_ft.compile(loss=dice_loss, optimizer=\"adam\", metrics=[dice_coef, soft_dice_coef])\n",
    "\n",
    "# Validate the INT8 model.\n",
    "test_nncf_ft_loss, test_nncf_ft_dice_coef, test_nncf_ft_soft_dice_coef = test_nncf_ft.evaluate(brats_datafiles.get_test())\n",
    "print(f\"\\nLoss of test_nncf INT8 model: {test_nncf_ft_loss:.3f}\\nDice Coef of test_nncf INT8 model: {test_nncf_ft_dice_coef:.3f}\\nSoft Dice Coef of test_nncf INT8 model: {test_nncf_ft_soft_dice_coef:.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b9cce8d-d6f9-41ee-b1a2-f8d1f36c65c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !mo -h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2fafdc9-8e9e-4787-a1c5-4e9502396ede",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !mo --framework=tf --input_shape=[1,128,128,128,1] --data_type \"FP32\" --input=data --input_model=$fp32_sm_path --output_dir=$OUTPUT_DIR\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "015d803b-0893-44d6-80d5-a0bde1ac1b0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "!mo --framework=tf --input_shape=[1,$tile_height,$tile_width,$tile_depth,$number_input_channels] --data_type \"FP32\" --input_model=$int8_ft_pb_path --output_dir=$OUTPUT_DIR\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb3bd82c-5320-490b-901e-c7374b71d586",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !mo --framework=tf --input_shape=[1,128,128,128,1] --input=Placeholder --input_model=$int8_pb_path --output_dir=$OUTPUT_DIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e605d2d9-5f4f-4637-a825-5d30130be94e",
   "metadata": {},
   "outputs": [],
   "source": [
    "openvino_filename = \"/home/ubuntu/unet/3D/3d_unet_decathlon/NNCF/output/3d_unet_int8\"\n",
    "path_to_xml_file = f\"{openvino_filename}.xml\"\n",
    "path_to_bin_file = f\"{openvino_filename}.bin\"\n",
    "\n",
    "ie = Core()\n",
    "model_int8 = ie.read_model(model=path_to_xml_file, weights=path_to_bin_file)\n",
    "compiled_model_int8 = ie.compile_model(model=modelmodel_int8, device_name=\"CPU\")\n",
    "\n",
    "del model_int8\n",
    "\n",
    "input_layer = next(iter(compiled_model_int8.inputs))\n",
    "output_layer = next(iter(compiled_model_int8.outputs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd8976ca-e7a2-47e1-ac3a-dc69e9c35b3f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c4db1c1-f895-4f07-b03e-a1c3b0c95f5d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8189802-b09e-4994-b1ab-bc0c7461067e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85704f3f-4374-4b08-8d9e-89bd9b05a841",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9378be8-a2c7-4938-9065-e7b5d0df3a86",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79fb0fda-adaf-4fd4-a809-fc5607989091",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b112a324-dd1b-4b42-97b4-e55c528eb43a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51f826b4-232f-4043-aef8-9d74178b32c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_benchmark_output(benchmark_output):\n",
    "    parsed_output = [line for line in benchmark_output if not (line.startswith(r\"[\") or line.startswith(\"  \") or line == \"\")]\n",
    "    print(*parsed_output, sep='\\n')\n",
    "\n",
    "\n",
    "print('Benchmark FP32 model (IR)')\n",
    "benchmark_output = ! benchmark_app -m $fp32_ir_path -d CPU -api async -t 15\n",
    "parse_benchmark_output(benchmark_output)\n",
    "\n",
    "print('\\nBenchmark INT8 model (IR)')\n",
    "benchmark_output = ! benchmark_app -m $int8_ir_path -d CPU -api async -t 15\n",
    "parse_benchmark_output(benchmark_output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bb948fb-0dbc-41a4-99ca-312137b31b35",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openvino.runtime import Core\n",
    "\n",
    "ie = Core()\n",
    "ie.get_property('CPU', \"FULL_DEVICE_NAME\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17598629-8be9-4afb-b9d3-046d369f4f52",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35ba2578-fbb1-4490-a4c7-83913a70d4fc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7866b8e0-a0ad-4857-8e2f-4da15fa3ecd3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c5495ef-a3d6-432c-87a1-b5f1948e2616",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "643e6b0b-a9f3-40e5-9a2e-c3f3ee8c459f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f91d8015-95d7-4cee-ae7c-b8e283078681",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3285333b-fc25-4fd8-8ae2-94c2a1a57bce",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fa53fea-eb66-4045-8c0b-7a6d7d88aa64",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfc616ad-1291-4ea5-a935-6e82bea574f7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8112dec7-c8f2-486b-9765-33ebf4643bdf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9926b275-b8d8-4e18-bd50-af05420848f6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d07bc065-ca88-43fa-aade-561e78741eae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99675f86-1f7f-4215-bb7f-67f8b55d706c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c5106a1-8dcf-44c9-a5ea-e1cb6a84694b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c3af882-e0d7-4c55-950d-f763b692bd79",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "def9ea80-1dc4-4676-a11e-4b9e4ba3775f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e61988c8-4b4a-466f-9aba-e6bdabe68be6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2efc819f-e0d7-419b-86e7-47fab46c8cbe",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nncf_model",
   "language": "python",
   "name": "nncf_model"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
