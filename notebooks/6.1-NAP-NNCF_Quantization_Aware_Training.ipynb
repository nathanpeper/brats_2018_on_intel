{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8a2c8b27-93c2-444e-9b12-52a6a9d40595",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['TF_ENABLE_ONEDNN_OPTS'] = '1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c54b1823-fb26-496c-bf58-d3c6b59b927e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import logging\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras as K\n",
    "#from tensorflow.python.keras import layers\n",
    "#from tensorflow.python.keras import models\n",
    "\n",
    "import nibabel as nib\n",
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "import datetime\n",
    "    \n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from nncf import NNCFConfig\n",
    "from nncf.tensorflow.helpers.model_creation import create_compressed_model\n",
    "from nncf.tensorflow.initialization import register_default_init_args\n",
    "from nncf.common.utils.logger import set_log_level\n",
    "\n",
    "sys.path.insert(0, \"/home/ubuntu/brats_2018_on_intel/src/\") # add path to find user-defined python models\n",
    "sys.path.insert(0, \"/home/ubuntu/miniconda3/envs/nncf_model/bin/\") # add path for kernel env due to launching jupyter from different env"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "532d2303-86f2-40ca-80d4-d2dc1d5f1808",
   "metadata": {},
   "source": [
    "Need to define a data path, original model path, and all created model paths\n",
    "\n",
    "tensorflow model in fp32 (h5 & pb)\n",
    "\n",
    "tensorflow + mo in various data types\n",
    "\n",
    "tensorflow + pot in various data types\n",
    "\n",
    "tensorflow + nncf \n",
    "\n",
    "tensorflow + nncf + mo in various datatypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c53be11-624d-4753-b718-1c45d47eb83c",
   "metadata": {},
   "source": [
    "models\n",
    "    base_model_name + framework + datatype\n",
    "    base_model_name + framework + openvino + datatype\n",
    "    base_model_name + framework + openvino + pot + datatype\n",
    "    base_model_name + framework + nncf + datatype\n",
    "    base_model_name + framework + nncf + openvino + datatype\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0fd73f6a-f2bd-4f3a-8ac5-183b003b15cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = \"/home/ubuntu/brats_2018_on_intel/data/processed/Task01_BrainTumour/\"\n",
    "DATA_DIR = \"/home/ubuntu/brats_2018_on_intel/data/processed/\"\n",
    "DATASET = \"Task01_BrainTumour/\"\n",
    "\n",
    "TRAIN_TEST_SPLIT = 0.80\n",
    "VALIDATE_TEST_SPLIT = 0.50\n",
    "\n",
    "BATCH_SIZE_TRAIN = 8\n",
    "BATCH_SIZE_VALIDATE = 4\n",
    "BATCH_SIZE_TEST = 1\n",
    "\n",
    "TILE_HEIGHT = 144\n",
    "TILE_WIDTH = 144\n",
    "TILE_DEPTH = 144\n",
    "NUMBER_INPUT_CHANNELS = 1\n",
    "\n",
    "CROP_DIM = (TILE_HEIGHT,TILE_WIDTH,TILE_DEPTH,NUMBER_INPUT_CHANNELS)\n",
    "\n",
    "NUMBER_OUTPUT_CLASSES = 1\n",
    "\n",
    "\n",
    "MODEL_DIR = \"/home/ubuntu/brats_2018_on_intel/models\"\n",
    "SAVED_MODEL_NAME = \"3d_unet_decathlon\"\n",
    "SELECTED_MODEL_EPOCH = 27\n",
    "\n",
    "FILTERS = 16\n",
    "NUM_EPOCHS = 40\n",
    "\n",
    "RANDOM_SEED = 64\n",
    "\n",
    "OUTPUT_DIR = Path(\"/home/ubuntu/brats_2018_on_intel/models/openvino\")\n",
    "IR_MODEL_PRECISION = \"FP32\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "80222c36-7499-43c3-b518-bd8d0726c3b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "set_log_level(logging.ERROR)\n",
    "\n",
    "MODEL_DIR = Path(MODEL_DIR)\n",
    "OUTPUT_DIR = Path(OUTPUT_DIR)\n",
    "\n",
    "MODEL_DIR.mkdir(parents=True, exist_ok=True)\n",
    "OUTPUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "\n",
    "# Path of baseline TF model with FP32 precision\n",
    "fp32_h5_path = Path(MODEL_DIR / SAVED_MODEL_NAME / SAVED_MODEL_NAME).with_suffix(\".h5\")\n",
    "fp32_sm_path = Path(MODEL_DIR / SAVED_MODEL_NAME / \"saved_model.pb\")\n",
    "\n",
    "# Path of optimized TF model using OpenVINO Model Optimizer with FP32 precision\n",
    "fp32_ir_name = Path(SAVED_MODEL_NAME + \"_\" + \"tf\" + \"_\" + \"ov\" + \"_\" + \"fp32\" + \"_ir\").with_suffix(\".xml\")\n",
    "fp32_ir_path = Path(OUTPUT_DIR / fp32_ir_name)\n",
    "\n",
    "# Path of compressed TF model using OpenVINO Neural Net Compression Framework with INT8 precision\n",
    "int8_pb_folder = Path(SAVED_MODEL_NAME + \"_\" + \"tf\" + \"_\" + \"nncf\" + \"_\" + \"int8\")#.with_suffix(\".pb\")\n",
    "int8_pb_path = Path(OUTPUT_DIR / int8_pb_folder)\n",
    "int8_pb_path.mkdir(parents=True, exist_ok=True)\n",
    "int8_pb_file = Path(int8_pb_path / \"saved_model\").with_suffix(\".pb\")\n",
    "\n",
    "\n",
    "# Path of finetuned, compressed TF model using OpenVINO Neural Net Compression Framework with INT8 precision\n",
    "int8_ft_pb_folder = Path(SAVED_MODEL_NAME + \"_\" + \"tf\" + \"_\" + \"nncf\" + \"_\" + \"ft_\"+ \"int8\")#.with_suffix(\".pb\")\n",
    "int8_ft_pb_path = Path(OUTPUT_DIR / int8_ft_pb_folder)\n",
    "int8_ft_pb_path.mkdir(parents=True, exist_ok=True)\n",
    "int8_ft_pb_file = Path(int8_ft_pb_path / \"saved_model\").with_suffix(\".pb\")\n",
    "\n",
    "# # Path of finetuned, compressed TF model using OpenVINO Neural Net Compression Framework with INT8 precision\n",
    "# int8_ft_pb_name = Path(SAVED_MODEL_NAME + \"_\" + \"tf\" + \"_\" + \"nncf\" + \"_\" + \"ft_\"+ \"int8\").with_suffix(\".pb\")\n",
    "# int8_ft_pb_path = Path(OUTPUT_DIR / int8_ft_pb_name)\n",
    "\n",
    "\n",
    "# Path of optimized, compressed TF model using OpenVINO Neural Net Compression Framework then Model Optimizer with INT8 precision\n",
    "int8_ir_name = Path(SAVED_MODEL_NAME + \"_\" + \"tf\" + \"_\" + \"nncf\" + \"_\" + \"ov\" + \"_\" + \"int8\" + \"_ir\").with_suffix(\".xml\")\n",
    "int8_ir_path = Path(OUTPUT_DIR / int8_ir_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "50a01ada-4d5a-499c-81e2-58ebe430d58d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_path=\"/home/ubuntu/unet/data/Task01_BrainTumour/\"\n",
    "# train_test_split = 0.80\n",
    "# validate_test_split = 0.50\n",
    "# batch_size_train = 8\n",
    "# batch_size_validate = 4\n",
    "# batch_size_test = 1\n",
    "# crop_dim = (128,128,128,1)\n",
    "# #crop_dim = (144,144,144,1)\n",
    "\n",
    "# tile_height = 128\n",
    "# tile_width = 128\n",
    "# tile_depth = 128\n",
    "# number_input_channels = 1\n",
    "\n",
    "# number_output_classes = 1\n",
    "# random_seed = 64\n",
    "\n",
    "# filters = 8\n",
    "# #saved_model_name = \"3d_unet_decathlon\"\n",
    "\n",
    "\n",
    "# num_epochs=30\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8692b515-0290-45f4-99f2-aab10f9ab51a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We are using Tensorflow version 2.5.3\n",
      "MKL enabled : True\n"
     ]
    }
   ],
   "source": [
    "def get_mkl_enabled_flag():\n",
    "\n",
    "    mkl_enabled = False\n",
    "    major_version = int(tf.__version__.split(\".\")[0])\n",
    "    minor_version = int(tf.__version__.split(\".\")[1])\n",
    "    if major_version >= 2:\n",
    "        if minor_version < 5:\n",
    "            from tensorflow.python import _pywrap_util_port\n",
    "        elif minor_version >= 9:\n",
    "\n",
    "            from tensorflow.python.util import _pywrap_util_port\n",
    "            onednn_enabled = int(os.environ.get('TF_ENABLE_ONEDNN_OPTS', '1'))\n",
    "\n",
    "        else:\n",
    "            from tensorflow.python.util import _pywrap_util_port\n",
    "            onednn_enabled = int(os.environ.get('TF_ENABLE_ONEDNN_OPTS', '0'))\n",
    "        mkl_enabled = _pywrap_util_port.IsMklEnabled() or (onednn_enabled == 1)\n",
    "    else:\n",
    "        mkl_enabled = tf.pywrap_tensorflow.IsMklEnabled()\n",
    "    return mkl_enabled\n",
    "\n",
    "print (\"We are using Tensorflow version\", tf.__version__)\n",
    "print(\"MKL enabled :\", get_mkl_enabled_flag())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "94b301e5-8cf9-4bc0-9d8e-aaa089058320",
   "metadata": {},
   "outputs": [],
   "source": [
    "from data.dataloader import DatasetGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ea800f5a-e209-4197-970a-0836b8217184",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==============================\n",
      "Dataset name:         BRATS\n",
      "Dataset description:  Gliomas segmentation tumour and oedema in on brain images\n",
      "Tensor image size:    4D\n",
      "Dataset release:      2.0 04/05/2018\n",
      "Dataset reference:    https://www.med.upenn.edu/sbia/brats2017.html\n",
      "Input channels:       {'0': 'FLAIR', '1': 'T1w', '2': 't1gd', '3': 'T2w'}\n",
      "Output labels:        {'0': 'background', '1': 'edema', '2': 'non-enhancing tumor', '3': 'enhancing tumour'}\n",
      "Dataset license:      CC-BY-SA 4.0\n",
      "==============================\n"
     ]
    }
   ],
   "source": [
    "brats_datafiles = DatasetGenerator(data_path=DATA_PATH, \n",
    "                                   train_test_split=TRAIN_TEST_SPLIT,\n",
    "                                   validate_test_split=VALIDATE_TEST_SPLIT,\n",
    "                                   batch_size_train=BATCH_SIZE_TRAIN,\n",
    "                                   batch_size_validate=BATCH_SIZE_VALIDATE,\n",
    "                                   batch_size_test=BATCH_SIZE_TEST,\n",
    "                                   tile_height=TILE_HEIGHT, \n",
    "                                   tile_width=TILE_WIDTH, \n",
    "                                   tile_depth=TILE_DEPTH, \n",
    "                                   number_input_channels=NUMBER_INPUT_CHANNELS,\n",
    "                                   number_output_classes=NUMBER_OUTPUT_CLASSES,\n",
    "                                   random_seed=RANDOM_SEED)\n",
    "brats_datafiles.print_info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e5b847bc-40d1-4354-9fe4-d3938f90a463",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and complie the baseline TF model with FP32 precision\n",
    "from models.model import dice_coef, soft_dice_coef, dice_loss\n",
    "tf_baseline_model_fp32 = tf.keras.models.load_model(fp32_h5_path, \n",
    "                                      compile=False, \n",
    "                                      custom_objects={\"dice_coef\":dice_coef, \"soft_dice_coef\":soft_dice_coef, \"dice_loss\":dice_loss})\n",
    "tf_baseline_model_fp32.compile(loss=dice_loss, optimizer=\"adam\", metrics=[dice_coef, soft_dice_coef])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "fa630182-20ef-4b8c-ad0e-8ba239738780",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49/49 [==============================] - 43s 777ms/step - loss: 1.5053 - dice_coef: 0.5961 - soft_dice_coef: 0.5936\n",
      "\n",
      "Loss of TF Baseline FP32 model: 1.505\n",
      "Dice Coef of FP32 model: 0.596\n",
      "Soft Dice Coef of FP32 model: 0.594\n"
     ]
    }
   ],
   "source": [
    "# Validate the model\n",
    "tf_baseline_fp32_loss, tf_baseline_fp32_dice_coef, tf_baseline_fp32_soft_dice_coef = tf_baseline_model_fp32.evaluate(brats_datafiles.get_test())\n",
    "print(f\"\\nLoss of TF Baseline FP32 model: {tf_baseline_fp32_loss:.3f}\\nDice Coef of FP32 model: {tf_baseline_fp32_dice_coef:.3f}\\nSoft Dice Coef of FP32 model: {tf_baseline_fp32_soft_dice_coef:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c6b44454-8fdf-4359-9901-deb5b74c0d0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "nncf_config_dict = {\n",
    "    \"input_info\": {\"sample_size\": [1, brats_datafiles.number_input_channels, brats_datafiles.tile_height, brats_datafiles.tile_width, brats_datafiles.tile_depth]},\n",
    "    \"log_dir\": str(OUTPUT_DIR),  # The log directory for NNCF-specific logging outputs.\n",
    "    \"compression\": {\n",
    "        \"algorithm\": \"quantization\",  # Specify the algorithm here.\n",
    "    },\n",
    "}\n",
    "nncf_config = NNCFConfig.from_dict(nncf_config_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a7428db3-b05e-4e1b-b8d4-73da301a8b8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "nncf_config = register_default_init_args(nncf_config=nncf_config,\n",
    "                                         data_loader=brats_datafiles.get_train(),\n",
    "                                         batch_size=brats_datafiles.batch_size_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d6802b72-81f1-4956-a739-287d6ac2d92a",
   "metadata": {},
   "outputs": [],
   "source": [
    "compression_ctrl, compressed_tf_model_int8 = create_compressed_model(tf_baseline_model_fp32, nncf_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7d844817-2645-4da8-9dcf-8695b8ae8e8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Absolute path where the int8 model is saved:\n",
      " /home/ubuntu/brats_2018_on_intel/models/openvino/3d_unet_decathlon_tf_nncf_int8/saved_model.pb\n"
     ]
    }
   ],
   "source": [
    "compression_ctrl.export_model(int8_pb_file, 'frozen_graph')\n",
    "print(f'Absolute path where the int8 model is saved:\\n {int8_pb_file.resolve()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0390b83b-d171-4801-a41a-4256a297a4c1",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index (0) out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_157047/3568636957.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m test_nncf = tf.keras.models.load_model(int8_pb_path, \n\u001b[1;32m      2\u001b[0m                                       \u001b[0mcompile\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m                                       custom_objects={\"dice_coef\":dice_coef, \"soft_dice_coef\":soft_dice_coef, \"dice_loss\":dice_loss})\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mtest_nncf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdice_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"adam\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdice_coef\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msoft_dice_coef\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/nncf_model/lib/python3.7/site-packages/tensorflow/python/keras/saving/save.py\u001b[0m in \u001b[0;36mload_model\u001b[0;34m(filepath, custom_objects, compile, options)\u001b[0m\n\u001b[1;32m    204\u001b[0m         \u001b[0mfilepath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpath_to_string\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 206\u001b[0;31m           \u001b[0;32mreturn\u001b[0m \u001b[0msaved_model_load\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    207\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m   raise IOError(\n",
      "\u001b[0;32m~/miniconda3/envs/nncf_model/lib/python3.7/site-packages/tensorflow/python/keras/saving/saved_model/load.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(path, compile, options)\u001b[0m\n\u001b[1;32m    119\u001b[0m   \u001b[0;31m# Look for metadata file or parse the SavedModel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m   \u001b[0mmetadata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msaved_metadata_pb2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSavedMetadata\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 121\u001b[0;31m   \u001b[0mmeta_graph_def\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloader_impl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparse_saved_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmeta_graphs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    122\u001b[0m   \u001b[0mobject_graph_def\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmeta_graph_def\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobject_graph_def\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m   \u001b[0mpath_to_metadata_pb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconstants\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSAVED_METADATA_PATH\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: list index (0) out of range"
     ]
    }
   ],
   "source": [
    "test_nncf = tf.keras.models.load_model(int8_pb_path, \n",
    "                                      compile=False, \n",
    "                                      custom_objects={\"dice_coef\":dice_coef, \"soft_dice_coef\":soft_dice_coef, \"dice_loss\":dice_loss})\n",
    "test_nncf.compile(loss=dice_loss, optimizer=\"adam\", metrics=[dice_coef, soft_dice_coef])\n",
    "\n",
    "# Validate the INT8 model.\n",
    "test_nncf_loss, test_nncf_dice_coef, test_nncf_soft_dice_coef = test_nncf.evaluate(brats_datafiles.get_test())\n",
    "print(f\"\\nLoss of test_nncf INT8 model: {test_nncf_loss:.3f}\\nDice Coef of test_nncf INT8 model: {test_nncf_dice_coef:.3f}\\nSoft Dice Coef of test_nncf INT8 model: {test_nncf_soft_dice_coef:.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eee3b9f0-67b7-44bd-b034-d6d61c54ce46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the INT8 model.\n",
    "compressed_tf_model_int8.compile(optimizer=\"adam\", \n",
    "              loss=dice_loss,\n",
    "              metrics=[dice_coef, soft_dice_coef])\n",
    "\n",
    "# Validate the INT8 model.\n",
    "compressed_tf_model_int8_loss, compressed_tf_model_int8_dice_coef, compressed_tf_model_int8_soft_dice_coef = compressed_tf_model_int8.evaluate(brats_datafiles.get_test())\n",
    "print(f\"\\nLoss of INT8 model: {compressed_tf_model_int8_loss:.3f}\\nDice Coef of INT8 model: {compressed_tf_model_int8_dice_coef:.3f}\\nSoft Dice Coef of INT8 model: {compressed_tf_model_int8_soft_dice_coef:.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6e49176-fdd4-4d02-b6e0-39137531a683",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the INT8 model.\n",
    "steps_per_epoch = brats_datafiles.num_train // brats_datafiles.batch_size_train\n",
    "\n",
    "compressed_tf_model_int8.fit(brats_datafiles.get_train(),\n",
    "          steps_per_epoch=steps_per_epoch,\n",
    "          epochs=2)\n",
    "\n",
    "# Validate the INT8 model.\n",
    "compressed_ft_tf_model_int8_loss, compressed_ft_tf_model_int8_dice_coef, compressed_ft_tf_model_int8_soft_dice_coef  = compressed_tf_model_int8.evaluate(brats_datafiles.get_test())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "054e15a0-f404-4c1d-ad92-a4cf9161a8c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(f\"\\nAccuracy drop of tuned INT8 model over pre-trained FP32 model: {acc_fp32 - acc_int8:.3f}\")\n",
    "print(f\"Loss of FP32 model: {tf_baseline_fp32_loss:.3f}\\nDice Coef of FP32 model: {tf_baseline_fp32_dice_coef:.3f}\\nSoft Dice Coef of FP32 model: {tf_baseline_fp32_soft_dice_coef:.3f}\")\n",
    "print(f\"\\nLoss of INT8 model: {compressed_tf_model_int8_loss:.3f}\\nDice Coef of INT8 model: {compressed_tf_model_int8_dice_coef:.3f}\\nSoft Dice Coef of INT8 model: {compressed_tf_model_int8_soft_dice_coef:.3f}\")\n",
    "print(f\"\\nLoss of Finetuned INT8 model: {compressed_ft_tf_model_int8_loss:.3f}\\nDice Coef of Finetuned INT8 model: {compressed_ft_tf_model_int8_dice_coef:.3f}\\nSoft Dice Coef of Finetuned INT8 model: {compressed_ft_tf_model_int8_soft_dice_coef:.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b13d9ee9-a496-4dd3-a552-aad44dc45758",
   "metadata": {},
   "outputs": [],
   "source": [
    "compressed_tf_model_int8.save(int8_ft_pb_path)\n",
    "print(f'Absolute path where the model is saved:\\n {int8_ft_pb_path.resolve()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfe5c6db-9d2c-4b4b-b991-6b186444a614",
   "metadata": {},
   "outputs": [],
   "source": [
    "from model import dice_coef, soft_dice_coef, dice_loss\n",
    "\n",
    "test_nncf_ft = tf.keras.models.load_model(int8_ft_pb_path, \n",
    "                                      compile=False, \n",
    "                                      custom_objects={\"dice_coef\":dice_coef, \"soft_dice_coef\":soft_dice_coef, \"dice_loss\":dice_loss})\n",
    "test_nncf_ft.compile(loss=dice_loss, optimizer=\"adam\", metrics=[dice_coef, soft_dice_coef])\n",
    "\n",
    "# Validate the INT8 model.\n",
    "test_nncf_ft_loss, test_nncf_ft_dice_coef, test_nncf_ft_soft_dice_coef = test_nncf_ft.evaluate(brats_datafiles.get_test())\n",
    "print(f\"\\nLoss of test_nncf INT8 model: {test_nncf_ft_loss:.3f}\\nDice Coef of test_nncf INT8 model: {test_nncf_ft_dice_coef:.3f}\\nSoft Dice Coef of test_nncf INT8 model: {test_nncf_ft_soft_dice_coef:.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b9cce8d-d6f9-41ee-b1a2-f8d1f36c65c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !mo -h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2fafdc9-8e9e-4787-a1c5-4e9502396ede",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !mo --framework=tf --input_shape=[1,128,128,128,1] --data_type \"FP32\" --input=data --input_model=$fp32_sm_path --output_dir=$OUTPUT_DIR\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "015d803b-0893-44d6-80d5-a0bde1ac1b0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "!mo --framework=tf --input_shape=[1,$tile_height,$tile_width,$tile_depth,$number_input_channels] --data_type \"FP32\" --input_model=$int8_ft_pb_path --output_dir=$OUTPUT_DIR\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb3bd82c-5320-490b-901e-c7374b71d586",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !mo --framework=tf --input_shape=[1,128,128,128,1] --input=Placeholder --input_model=$int8_pb_path --output_dir=$OUTPUT_DIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e605d2d9-5f4f-4637-a825-5d30130be94e",
   "metadata": {},
   "outputs": [],
   "source": [
    "openvino_filename = \"/home/ubuntu/unet/3D/3d_unet_decathlon/NNCF/output/3d_unet_int8\"\n",
    "path_to_xml_file = f\"{openvino_filename}.xml\"\n",
    "path_to_bin_file = f\"{openvino_filename}.bin\"\n",
    "\n",
    "ie = Core()\n",
    "model_int8 = ie.read_model(model=path_to_xml_file, weights=path_to_bin_file)\n",
    "compiled_model_int8 = ie.compile_model(model=modelmodel_int8, device_name=\"CPU\")\n",
    "\n",
    "del model_int8\n",
    "\n",
    "input_layer = next(iter(compiled_model_int8.inputs))\n",
    "output_layer = next(iter(compiled_model_int8.outputs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd8976ca-e7a2-47e1-ac3a-dc69e9c35b3f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c4db1c1-f895-4f07-b03e-a1c3b0c95f5d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8189802-b09e-4994-b1ab-bc0c7461067e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85704f3f-4374-4b08-8d9e-89bd9b05a841",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9378be8-a2c7-4938-9065-e7b5d0df3a86",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79fb0fda-adaf-4fd4-a809-fc5607989091",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b112a324-dd1b-4b42-97b4-e55c528eb43a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51f826b4-232f-4043-aef8-9d74178b32c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_benchmark_output(benchmark_output):\n",
    "    parsed_output = [line for line in benchmark_output if not (line.startswith(r\"[\") or line.startswith(\"  \") or line == \"\")]\n",
    "    print(*parsed_output, sep='\\n')\n",
    "\n",
    "\n",
    "print('Benchmark FP32 model (IR)')\n",
    "benchmark_output = ! benchmark_app -m $fp32_ir_path -d CPU -api async -t 15\n",
    "parse_benchmark_output(benchmark_output)\n",
    "\n",
    "print('\\nBenchmark INT8 model (IR)')\n",
    "benchmark_output = ! benchmark_app -m $int8_ir_path -d CPU -api async -t 15\n",
    "parse_benchmark_output(benchmark_output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bb948fb-0dbc-41a4-99ca-312137b31b35",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openvino.runtime import Core\n",
    "\n",
    "ie = Core()\n",
    "ie.get_property('CPU', \"FULL_DEVICE_NAME\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17598629-8be9-4afb-b9d3-046d369f4f52",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35ba2578-fbb1-4490-a4c7-83913a70d4fc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7866b8e0-a0ad-4857-8e2f-4da15fa3ecd3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c5495ef-a3d6-432c-87a1-b5f1948e2616",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "643e6b0b-a9f3-40e5-9a2e-c3f3ee8c459f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f91d8015-95d7-4cee-ae7c-b8e283078681",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3285333b-fc25-4fd8-8ae2-94c2a1a57bce",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fa53fea-eb66-4045-8c0b-7a6d7d88aa64",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfc616ad-1291-4ea5-a935-6e82bea574f7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8112dec7-c8f2-486b-9765-33ebf4643bdf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9926b275-b8d8-4e18-bd50-af05420848f6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d07bc065-ca88-43fa-aade-561e78741eae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99675f86-1f7f-4215-bb7f-67f8b55d706c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c5106a1-8dcf-44c9-a5ea-e1cb6a84694b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c3af882-e0d7-4c55-950d-f763b692bd79",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "def9ea80-1dc4-4676-a11e-4b9e4ba3775f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e61988c8-4b4a-466f-9aba-e6bdabe68be6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2efc819f-e0d7-419b-86e7-47fab46c8cbe",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nncf_model",
   "language": "python",
   "name": "nncf_model"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
