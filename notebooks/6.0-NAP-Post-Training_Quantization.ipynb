{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1c85d0d4-a7c4-474b-b080-8373083a399c",
   "metadata": {},
   "source": [
    "https://docs.openvino.ai/latest/notebooks/301-tensorflow-training-openvino-pot-with-output.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cfde49cc-df46-4ec8-bda7-e43962b91b37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/brats_2018_on_intel/notebooks\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0d7a40d2-5619-4031-8da8-c61afa1c5761",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-08 23:17:27.087153: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-09-08 23:17:27.087185: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "import copy\n",
    "import os\n",
    "import sys\n",
    "import urllib\n",
    "import time\n",
    "from pathlib import Path\n",
    "\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from addict import Dict\n",
    "\n",
    "from openvino.tools.pot.api import Metric, DataLoader\n",
    "from openvino.tools.pot.graph import load_model, save_model\n",
    "from openvino.tools.pot.graph.model_utils import compress_model_weights\n",
    "from openvino.tools.pot.engines.ie_engine import IEEngine\n",
    "from openvino.tools.pot.pipeline.initializer import create_pipeline\n",
    "from openvino.runtime import Core\n",
    "\n",
    "sys.path.append(\"../utils\")\n",
    "# from notebook_utils import benchmark_model\n",
    "\n",
    "import sys\n",
    "sys.path.insert(0, \"/home/ubuntu/brats_2018_on_intel/src/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c65774a2-7916-4334-b514-8c44bc4ddc45",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_add = \"/home/ubuntu/miniconda3/envs/optimize_model/\"\n",
    "os.environ[\"PATH\"] += os.pathsep + path_to_add"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c8b9fc4d-221f-4e0c-bc16-ef4c111f987d",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = \"/home/ubuntu/brats_2018_on_intel/data/processed/Task01_BrainTumour/\"\n",
    "DATA_DIR = \"/home/ubuntu/brats_2018_on_intel/data/processed/\"\n",
    "DATASET = \"Task01_BrainTumour/\"\n",
    "\n",
    "TRAIN_TEST_SPLIT = 0.80\n",
    "VALIDATE_TEST_SPLIT = 0.50\n",
    "\n",
    "BATCH_SIZE_TRAIN = 8\n",
    "BATCH_SIZE_VALIDATE = 4\n",
    "BATCH_SIZE_TEST = 1\n",
    "\n",
    "TILE_HEIGHT = 144\n",
    "TILE_WIDTH = 144\n",
    "TILE_DEPTH = 144\n",
    "NUMBER_INPUT_CHANNELS = 1\n",
    "\n",
    "CROP_DIM = (TILE_HEIGHT,TILE_WIDTH,TILE_DEPTH,NUMBER_INPUT_CHANNELS)\n",
    "\n",
    "NUMBER_OUTPUT_CLASSES = 1\n",
    "\n",
    "\n",
    "MODEL_DIR = \"/home/ubuntu/brats_2018_on_intel/models\"\n",
    "SAVED_MODEL_NAME = \"3d_unet_decathlon\"\n",
    "SELECTED_MODEL_EPOCH = 27\n",
    "\n",
    "FILTERS = 16\n",
    "NUM_EPOCHS = 40\n",
    "\n",
    "RANDOM_SEED = 64\n",
    "\n",
    "OUTPUT_DIR = Path(\"/home/ubuntu/brats_2018_on_intel/models/openvino\")\n",
    "IR_MODEL_PRECISION = \"FP32\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "996b9cf7-3e7d-4368-87b5-8ce82428ae69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/brats_2018_on_intel/models/openvino/3d_unet_decathlon_tf_ov_fp32_ir.xml\n",
      "/home/ubuntu/brats_2018_on_intel/models/openvino/3d_unet_decathlon_tf_ov_fp32_ir.bin\n"
     ]
    }
   ],
   "source": [
    "saved_model_path = Path(Path(MODEL_DIR) / SAVED_MODEL_NAME)\n",
    "\n",
    "fp32_ir_name = Path(SAVED_MODEL_NAME + \"_\" + \"tf\" + \"_\" + \"ov\" + \"_\" + \"fp32\" + \"_ir\")\n",
    "fp32_ir_path = Path(OUTPUT_DIR / fp32_ir_name)\n",
    "\n",
    "pot_int8_ir_name = Path(SAVED_MODEL_NAME + \"_\" + \"tf\" + \"_\" + \"ov\" + \"_\" + \"pot\" + \"_\" + \"int8\" + \"_ir\")\n",
    "pot_int8_ir_path = Path(OUTPUT_DIR / pot_int8_ir_name)\n",
    "\n",
    "path_to_xml_file = f\"{fp32_ir_path}.xml\"\n",
    "print(path_to_xml_file)\n",
    "path_to_bin_file = f\"{fp32_ir_path}.bin\"\n",
    "print(path_to_bin_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfbbeb4c-0cc7-4ba5-8936-e3b9e403b95b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a7afe9fe-8783-4b3b-aa76-01284215dedd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from data.dataloader import DatasetGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a6d78424-a764-4c1c-960d-d6abbce79cda",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-08 23:17:53.021306: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/ubuntu/miniconda3/envs/optimize_model/lib/python3.7/site-packages/cv2/../../lib64:\n",
      "2022-09-08 23:17:53.021337: W tensorflow/stream_executor/cuda/cuda_driver.cc:326] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2022-09-08 23:17:53.021353: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (ip-10-1-35-172): /proc/driver/nvidia/version does not exist\n",
      "2022-09-08 23:17:53.021652: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "brats_datafiles = DatasetGenerator(data_path=DATA_PATH, \n",
    "                                   train_test_split=TRAIN_TEST_SPLIT,\n",
    "                                   validate_test_split=VALIDATE_TEST_SPLIT,\n",
    "                                   batch_size_train=BATCH_SIZE_TRAIN,\n",
    "                                   batch_size_validate=BATCH_SIZE_VALIDATE,\n",
    "                                   batch_size_test=BATCH_SIZE_TEST,\n",
    "                                   tile_height=TILE_HEIGHT, \n",
    "                                   tile_width=TILE_WIDTH, \n",
    "                                   tile_depth=TILE_DEPTH, \n",
    "                                   number_input_channels=NUMBER_INPUT_CHANNELS,\n",
    "                                   number_output_classes=NUMBER_OUTPUT_CLASSES,\n",
    "                                   random_seed=RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c37fc46d-4e64-4048-a97b-a97327f47b0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDataLoader(DataLoader):\n",
    "\n",
    "    def __init__(self, config):\n",
    "\n",
    "        super().__init__(config)\n",
    "\n",
    "        \"\"\"\n",
    "        You can define this data loader to work with your custom dataset.\n",
    "        In our case, we've already defined a TensorFlow `tf.data` object.\n",
    "        We'll just pass that to the API's data loader and transpose the images and masks\n",
    "        (OpenVINO assumes the data is channels first-- NCHWD)\n",
    "        \"\"\"\n",
    "\n",
    "        self.items = np.arange(config[\"num_samples\"])  # Just pass in how many samples you want to take\n",
    "        self.dataset = config[\"test_dataset\"]\n",
    "\n",
    "        print(\"\\nQuantizing FP32 OpenVINO model to INT8\\n\")\n",
    "\n",
    "        print(f\"Taking {len(self.items):,} random samples from the test dataset\")\n",
    "\n",
    "        self.batch_size = 1\n",
    "\n",
    "    def set_subset(self, indices):\n",
    "        self._subset = None\n",
    "\n",
    "    @property\n",
    "    def batch_num(self):\n",
    "        return ceil(self.size / self.batch_size)\n",
    "\n",
    "    @property\n",
    "    def size(self):\n",
    "        return self.items.shape[0]\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.size\n",
    "\n",
    "    def __getitem__(self, item):\n",
    "        \"\"\"\n",
    "        \"\"\"\n",
    "        ds = self.dataset.take(1).as_numpy_iterator()  # Grab the next batch and take a single element (image/mask)\n",
    "        for img, msk in ds:\n",
    "            img = np.transpose(img, [0,4,1,2,3])  # OpenVINO expects the input to be channels first (NCHWD)\n",
    "            msk = np.transpose(msk, [0,4,1,2,3])  # OpenVINO expects the label/output to be channels first (NCHWD)\n",
    "        \n",
    "        return (item, msk), img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "959fae63-0782-4107-af18-9b2b5ffbef76",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyMetric(Metric):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.name = \"custom Metric - Dice score\"\n",
    "        self._values = []\n",
    "        self.round = 1\n",
    "\n",
    "    @property\n",
    "    def value(self):\n",
    "        \"\"\" Returns accuracy metric value for the last model output. \"\"\"\n",
    "        return {self.name: [self._values[-1]]}\n",
    "\n",
    "    @property\n",
    "    def avg_value(self):\n",
    "        \"\"\" Returns accuracy metric value for all model outputs. \"\"\"\n",
    "        value = np.ravel(self._values).mean()\n",
    "        print(\"Round #{}    Mean {} = {}\".format(self.round, self.name, value))\n",
    "\n",
    "        self.round += 1\n",
    "\n",
    "        return {self.name: value}\n",
    "\n",
    "    def update(self, outputs, labels):\n",
    "        \"\"\" Updates prediction matches.\n",
    "        Args:\n",
    "            outputs: model output\n",
    "            labels: annotations\n",
    "        Put your post-processing code here.\n",
    "        Put your custom metric code here.\n",
    "        The metric gets appended to the list of metric values\n",
    "        \"\"\"\n",
    "\n",
    "        def dice_score(pred, truth):\n",
    "            \"\"\"\n",
    "            Sorensen Dice score\n",
    "            Measure of the overlap between the prediction and ground truth masks\n",
    "            \"\"\"\n",
    "            numerator = np.sum(np.round(pred) * truth) * 2.0\n",
    "            denominator = np.sum(np.round(pred)) + np.sum(truth)\n",
    "\n",
    "            return numerator / denominator\n",
    "\n",
    "\n",
    "        metric = dice_score(labels[0], outputs[0])\n",
    "        self._values.append(metric)\n",
    "\n",
    "    def reset(self):\n",
    "        \"\"\" Resets collected matches \"\"\"\n",
    "        self._values = []\n",
    "\n",
    "    @property\n",
    "    def higher_better(self):\n",
    "        \"\"\"Attribute whether the metric should be increased\"\"\"\n",
    "        return True\n",
    "\n",
    "    def get_attributes(self):\n",
    "        return {self.name: {\"direction\": \"higher-better\", \"type\": \"\"}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b85e5d26-c164-4c16-a79b-0d7857e961e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "maximum_metric_drop = 0.05  # For accuracy-aware training. this defines how much the metric is allowed to change.\n",
    "accuracy_aware_quantization=True\n",
    "\n",
    "\n",
    "dataset_config = {\n",
    "    \"num_samples\": 40,   # Get 40 samples\n",
    "    \"test_dataset\": brats_datafiles.get_test()   # Pass our TensorFlow data loader to the API\n",
    "}\n",
    "\n",
    "# Model config specifies the model name and paths to model .xml and .bin file\n",
    "model_config = Dict(\n",
    "    {\n",
    "        \"model_name\": pot_int8_ir_name,\n",
    "        \"model\": path_to_xml_file,\n",
    "        \"weights\": path_to_bin_file\n",
    "    }\n",
    ")\n",
    "\n",
    "\n",
    "engine_config = Dict({\n",
    "    \"device\": \"CPU\",\n",
    "    \"stat_requests_number\": 4,\n",
    "    \"eval_requests_number\": 4\n",
    "})\n",
    "\n",
    "default_quantization_algorithm = [\n",
    "    {\n",
    "        \"name\": \"DefaultQuantization\",\n",
    "        \"params\": {\n",
    "            \"target_device\": \"CPU\",\n",
    "            \"preset\": \"performance\",\n",
    "            #\"stat_subset_size\": 10\n",
    "        }\n",
    "    }\n",
    "]\n",
    "\n",
    "accuracy_aware_quantization_algorithm = [\n",
    "    {\n",
    "        \"name\": \"AccuracyAwareQuantization\", # compression algorithm name\n",
    "        \"params\": {\n",
    "            \"target_device\": \"CPU\",\n",
    "            \"preset\": \"performance\",\n",
    "            \"stat_subset_size\": 10,\n",
    "            \"metric_subset_ratio\": 0.5, # A part of the validation set that is used to compare full-precision and quantized models\n",
    "            \"ranking_subset_size\": 300, # A size of a subset which is used to rank layers by their contribution to the accuracy drop\n",
    "            \"max_iter_num\": 10,    # Maximum number of iterations of the algorithm (maximum of layers that may be reverted back to full-precision)\n",
    "            \"maximal_drop\": maximum_metric_drop,      # Maximum metric drop which has to be achieved after the quantization\n",
    "            \"drop_type\": \"absolute\",    # Drop type of the accuracy metric: relative or absolute (default)\n",
    "            \"use_prev_if_drop_increase\": True,     # Whether to use NN snapshot from the previous algorithm iteration in case if drop increases\n",
    "            \"base_algorithm\": \"DefaultQuantization\" # Base algorithm that is used to quantize model at the beginning\n",
    "        }\n",
    "    }\n",
    "]\n",
    "\n",
    "class GraphAttrs(object):\n",
    "    def __init__(self):\n",
    "        self.keep_quantize_ops_in_IR = True\n",
    "        self.keep_shape_ops = False\n",
    "        self.data_type = \"FP32\"\n",
    "        self.progress = False\n",
    "        self.generate_experimental_IR_V10 = True\n",
    "        self.blobs_as_inputs = True\n",
    "        self.generate_deprecated_IR_V7 = False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "98048c4d-edc1-49c8-a925-a19fd9edb52f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Quantizing FP32 OpenVINO model to INT8\n",
      "\n",
      "Taking 40 random samples from the test dataset\n",
      "Accuracy-aware quantization method\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-08 23:18:00.379241: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:176] None of the MLIR Optimization Passes are enabled (registered 2)\n",
      "2022-09-08 23:18:00.397044: I tensorflow/core/platform/profile_utils/cpu_utils.cc:114] CPU Frequency: 2899975000 Hz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Round #1    Mean custom Metric - Dice score = 6.014788227090376\n",
      "Round #2    Mean custom Metric - Dice score = 5.485410646802075\n",
      "Round #3    Mean custom Metric - Dice score = 5.219891631187945\n",
      "Round #4    Mean custom Metric - Dice score = 19.096018631223835\n",
      "Round #5    Mean custom Metric - Dice score = 6.595300398415693\n",
      "Round #6    Mean custom Metric - Dice score = 5.844213650204565\n",
      "\n",
      "FINAL RESULTS\n",
      "custom Metric - Dice score  FP32: 6.014788227090376\n",
      "custom Metric - Dice score  INT8: 5.844213650204565\n",
      "\n",
      "The INT8 version of the model has been saved to the directory /home/ubuntu/brats_2018_on_intel/models/openvino/3d_unet_decathlon_tf_ov_pot_int8_ir\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = load_model(model_config=model_config)\n",
    "\n",
    "data_loader = MyDataLoader(dataset_config)\n",
    "\n",
    "metric = MyMetric()\n",
    "\n",
    "\n",
    "engine = IEEngine(config=engine_config, \n",
    "                  data_loader=data_loader, \n",
    "                  metric=metric)\n",
    "\n",
    "if accuracy_aware_quantization:\n",
    "    # https://docs.openvinotoolkit.org/latest/_compression_algorithms_quantization_accuracy_aware_README.html\n",
    "    print(\"Accuracy-aware quantization method\")\n",
    "    pipeline = create_pipeline(accuracy_aware_quantization_algorithm, engine)\n",
    "else:\n",
    "    print(\"Default quantization method\")\n",
    "    pipeline = create_pipeline(default_quantization_algorithm, engine)\n",
    "\n",
    "\n",
    "metric_results_FP32 = pipeline.evaluate(model)\n",
    "\n",
    "compressed_model = pipeline.run(model=model)\n",
    "#compress_model_weights(compressed_model)\n",
    "\n",
    "save_model(model=compressed_model, \n",
    "           save_path=pot_int8_ir_path)\n",
    "\n",
    "metric_results_INT8 = pipeline.evaluate(compressed_model)\n",
    "\n",
    "\n",
    "print(\"\\nFINAL RESULTS\")\n",
    "\n",
    "# print metric value\n",
    "if metric_results_FP32:\n",
    "    for name, value in metric_results_FP32.items():\n",
    "        print(f\"{name: <27s} FP32: {value}\")\n",
    "\n",
    "if metric_results_INT8:\n",
    "    for name, value in metric_results_INT8.items():\n",
    "        print(f\"{name: <27s} INT8: {value}\")\n",
    "\n",
    "\n",
    "print(f\"\\nThe INT8 version of the model has been saved to the directory {pot_int8_ir_path}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01d4cd40-3dfd-4855-9553-3099063ae995",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fb4589c-892d-4cf3-8343-fc21c9fa43a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "ie = Core()\n",
    "model = ie.read_model(model=path_to_xml_file, weights=path_to_bin_file)\n",
    "compiled_model = ie.compile_model(model=model, device_name=\"CPU\")\n",
    "\n",
    "del model\n",
    "\n",
    "input_layer_name = next(iter(compiled_model.inputs))\n",
    "output_layer_name = next(iter(compiled_model.outputs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09262cc9-383d-46da-9df3-b51481628f22",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4ac532d-9837-4b92-be9a-3d74a6e661f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "openvino_filename_int8 = os.path.join(int8_directory, openvino_modelname)\n",
    "path_to_xml_file_int8 = f\"{openvino_filename_int8}.xml\"\n",
    "path_to_bin_file_int8 = f\"{openvino_filename_int8}.bin\"\n",
    "\n",
    "ie_int8 = Core()\n",
    "model_int8 = ie.read_model(model=path_to_xml_file_int8, weights=path_to_bin_file_int8)\n",
    "compiled_model_int8 = ie.compile_model(model=model_int8, device_name=\"CPU\")\n",
    "\n",
    "del model_int8\n",
    "\n",
    "input_layer_name_int8 = next(iter(compiled_model_int8.inputs))\n",
    "output_layer_name_int8 = next(iter(compiled_model_int8.outputs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c5b36a0-7414-4aa6-8221-0dcd7f0035af",
   "metadata": {},
   "outputs": [],
   "source": [
    "from model import dice_coef, soft_dice_coef, dice_loss\n",
    "tf_model = tf.keras.models.load_model(\"/home/ubuntu/unet/3D/3d_unet_decathlon/3d_unet_decathlon.h5\", \n",
    "                                      compile=True, \n",
    "                                      custom_objects={\"dice_coef\":dice_coef, \"soft_dice_coef\":soft_dice_coef, \"dice_loss\":dice_loss})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfb5fc19-156d-4f44-86a3-95185f5a456e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_predictions(img_batch, msk_batch):\n",
    "    for i in range(img_batch.shape[0]):\n",
    "        img = img_batch[i:i+1,:,:,:,:]\n",
    "        msk = msk_batch[i:i+1,:,:,:,:]    \n",
    "    \n",
    "        slicenum=np.argmax(np.sum(msk, axis=(1,2)))  # Find the slice with the largest tumor section\n",
    "\n",
    "        plt.figure(figsize=(20,20))\n",
    "\n",
    "        plt.subplot(1,5,1)\n",
    "        plt.title(\"MRI\", fontsize=20)\n",
    "        plt.imshow(img[0,:,:,slicenum,0], cmap=\"gray\")\n",
    "        plt.subplot(1,5,2)\n",
    "        plt.imshow(msk[0,:,:,slicenum,0], cmap=\"gray\")\n",
    "        plt.title(\"Ground truth\", fontsize=20)\n",
    "\n",
    "        \n",
    "        \"\"\"\n",
    "        TensorFlow Model Prediction\n",
    "        \"\"\"\n",
    "        start_time = time.time()\n",
    "        prediction_tf = tf_model.predict(img)\n",
    "        inference_time_tf = 1000.0*(time.time()-start_time)\n",
    "        prediction_tf = tf.round(prediction_tf)\n",
    "        dice_coef_tf = dice_coef(msk,prediction_tf)\n",
    "\n",
    "        plt.subplot(1,5,3)\n",
    "        plt.imshow(prediction_tf[0,:,:,slicenum,0], cmap=\"gray\")\n",
    "        plt.title(f\"TensorFlow Prediction\\nFP32\\nDice = {dice_coef_tf:.4f}\\n\\nInference time\\n{inference_time_tf:.4f} msecs\", fontsize=20)\n",
    "\n",
    "        \n",
    "        \n",
    "        \"\"\"\n",
    "        OpenVINO Model Prediction - FP32\n",
    "        Note: OpenVINO assumes the input (and output) are organized as channels first (NCHWD)\n",
    "        whereas TensorFlow assumes channels last (NHWDC). We'll use the NumPy transpose\n",
    "        to change the order.\n",
    "        \"\"\"\n",
    "        start_time = time.time()\n",
    "        request = compiled_model.create_infer_request()\n",
    "        request.infer(inputs={input_layer_name.any_name: img})\n",
    "        prediction_ov = request.get_output_tensor(output_layer_name.index).data\n",
    "        inference_time_ov = 1000.0*(time.time()-start_time)\n",
    "        prediction_ov = tf.round(prediction_ov)\n",
    "        dice_coef_ov = dice_coef(msk,prediction_ov)\n",
    "\n",
    "        plt.subplot(1,5,4)\n",
    "        plt.imshow(prediction_ov[0,:,:,slicenum,0], cmap=\"gray\")\n",
    "        plt.title(f\"OpenVINO Prediction\\nFP32\\nDice = {dice_coef_ov:.4f}\\n\\nInference time\\n{inference_time_ov:.4f} msecs\", fontsize=20)\n",
    "\n",
    "        \n",
    "        \"\"\"\n",
    "        OpenVINO Model Prediction - INT8\n",
    "        Note: OpenVINO assumes the input (and output) are organized as channels first (NCHWD)\n",
    "        whereas TensorFlow assumes channels last (NHWDC). We'll use the NumPy transpose\n",
    "        to change the order.\n",
    "        \"\"\"\n",
    "        start_time = time.time()\n",
    "        request_int8 = compiled_model_int8.create_infer_request()\n",
    "        request_int8.infer(inputs={input_layer_name_int8.any_name: img})\n",
    "        prediction_ov_int8 = request_int8.get_output_tensor(output_layer_name_int8.index).data\n",
    "        inference_time_ov_int8 = 1000.0*(time.time()-start_time)\n",
    "        prediction_ov_int8 = tf.round(prediction_ov_int8)\n",
    "        dice_coef_ov_int8 = dice_coef(msk,prediction_ov_int8)\n",
    "\n",
    "        plt.subplot(1,5,5)\n",
    "        plt.imshow(prediction_ov_int8[0,:,:,slicenum,0], cmap=\"gray\")\n",
    "        plt.title(f\"OpenVINO Prediction\\nINT8\\nDice = {dice_coef_ov_int8:.4f}\\n\\nInference time\\n{inference_time_ov_int8:.4f} msecs\", fontsize=20)\n",
    "\n",
    "\n",
    "        \n",
    "        import pickle\n",
    "\n",
    "        data = {'img': img, \n",
    "                'msk': msk, \n",
    "                'prediction_ov_int8': prediction_ov_int8, \n",
    "                'dice_coef_ov_int8': dice_coef_ov_int8,\n",
    "                'inference_time_ov_int8': inference_time_ov_int8,\n",
    "                'prediction_ov': prediction_ov, \n",
    "                'dice_coef_ov': dice_coef_ov,\n",
    "                'inference_time_ov': inference_time_ov,\n",
    "                'prediction_tf': prediction_tf, \n",
    "                'dice_coef_tf': dice_coef_tf,\n",
    "                'inference_time_tf': inference_time_tf\n",
    "               }\n",
    "\n",
    "        # data = [img, msk, prediction_ov, dice_coef_ov, prediction_tf, dice_coef_tf]\n",
    "\n",
    "        with open('/home/ubuntu/unet/data/prediction_results.pkl', 'wb') as outfile:\n",
    "            pickle.dump(data, outfile, pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "        # with open('mat.pkl', 'rb') as infile:\n",
    "        #     result = pickle.load(infile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3638bf7b-f6ca-4e39-80e1-f95f293a049f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "ds = brats_datafiles.get_train().take(1).as_numpy_iterator()\n",
    "for img, msk in ds:\n",
    "    plot_predictions(img,msk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f86daa2-16e1-49e5-9c74-7020081bc11a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "optimize_model",
   "language": "python",
   "name": "optimize_model"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
