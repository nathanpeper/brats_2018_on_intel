{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1c85d0d4-a7c4-474b-b080-8373083a399c",
   "metadata": {},
   "source": [
    "https://docs.openvino.ai/latest/notebooks/301-tensorflow-training-openvino-pot-with-output.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cfde49cc-df46-4ec8-bda7-e43962b91b37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/brats_2018_on_intel/notebooks\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0d7a40d2-5619-4031-8da8-c61afa1c5761",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-08 22:30:46.809788: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-09-08 22:30:46.809816: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "import copy\n",
    "import os\n",
    "import sys\n",
    "import urllib\n",
    "import time\n",
    "from pathlib import Path\n",
    "\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from addict import Dict\n",
    "\n",
    "from openvino.tools.pot.api import Metric, DataLoader\n",
    "from openvino.tools.pot.graph import load_model, save_model\n",
    "from openvino.tools.pot.graph.model_utils import compress_model_weights\n",
    "from openvino.tools.pot.engines.ie_engine import IEEngine\n",
    "from openvino.tools.pot.pipeline.initializer import create_pipeline\n",
    "from openvino.runtime import Core\n",
    "\n",
    "sys.path.append(\"../utils\")\n",
    "# from notebook_utils import benchmark_model\n",
    "\n",
    "import sys\n",
    "sys.path.insert(0, \"/home/ubuntu/brats_2018_on_intel/src/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c65774a2-7916-4334-b514-8c44bc4ddc45",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_add = \"/home/ubuntu/miniconda3/envs/optimize_model/\"\n",
    "os.environ[\"PATH\"] += os.pathsep + path_to_add"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c8b9fc4d-221f-4e0c-bc16-ef4c111f987d",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = \"/home/ubuntu/brats_2018_on_intel/data/processed/Task01_BrainTumour/\"\n",
    "DATA_DIR = \"/home/ubuntu/brats_2018_on_intel/data/processed/\"\n",
    "DATASET = \"Task01_BrainTumour/\"\n",
    "\n",
    "TRAIN_TEST_SPLIT = 0.80\n",
    "VALIDATE_TEST_SPLIT = 0.50\n",
    "\n",
    "BATCH_SIZE_TRAIN = 8\n",
    "BATCH_SIZE_VALIDATE = 4\n",
    "BATCH_SIZE_TEST = 1\n",
    "\n",
    "TILE_HEIGHT = 144\n",
    "TILE_WIDTH = 144\n",
    "TILE_DEPTH = 144\n",
    "NUMBER_INPUT_CHANNELS = 1\n",
    "\n",
    "CROP_DIM = (TILE_HEIGHT,TILE_WIDTH,TILE_DEPTH,NUMBER_INPUT_CHANNELS)\n",
    "\n",
    "NUMBER_OUTPUT_CLASSES = 1\n",
    "\n",
    "\n",
    "MODEL_DIR = \"/home/ubuntu/brats_2018_on_intel/models\"\n",
    "SAVED_MODEL_NAME = \"3d_unet_decathlon\"\n",
    "SELECTED_MODEL_EPOCH = 27\n",
    "\n",
    "FILTERS = 16\n",
    "NUM_EPOCHS = 40\n",
    "\n",
    "RANDOM_SEED = 64\n",
    "\n",
    "OUTPUT_DIR = Path(\"/home/ubuntu/brats_2018_on_intel/models/openvino\")\n",
    "IR_MODEL_PRECISION = \"FP32\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "996b9cf7-3e7d-4368-87b5-8ce82428ae69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/brats_2018_on_intel/models/openvino/3d_unet_decathlon_tf_ov_fp32_ir.xml\n",
      "/home/ubuntu/brats_2018_on_intel/models/openvino/3d_unet_decathlon_tf_ov_fp32_ir.bin\n"
     ]
    }
   ],
   "source": [
    "saved_model_path = Path(Path(MODEL_DIR) / SAVED_MODEL_NAME)\n",
    "\n",
    "fp32_ir_name = Path(SAVED_MODEL_NAME + \"_\" + \"tf\" + \"_\" + \"ov\" + \"_\" + \"fp32\" + \"_ir\")\n",
    "fp32_ir_path = Path(OUTPUT_DIR / fp32_ir_name)\n",
    "\n",
    "pot_int8_ir_name = Path(SAVED_MODEL_NAME + \"_\" + \"tf\" + \"_\" + \"ov\" + \"_\" + \"pot\" + \"_\" + \"int8\" + \"_ir\")\n",
    "pot_int8_ir_path = Path(OUTPUT_DIR / pot_int8_ir_name)\n",
    "\n",
    "path_to_xml_file = f\"{fp32_ir_path}.xml\"\n",
    "print(path_to_xml_file)\n",
    "path_to_bin_file = f\"{fp32_ir_path}.bin\"\n",
    "print(path_to_bin_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfbbeb4c-0cc7-4ba5-8936-e3b9e403b95b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a7afe9fe-8783-4b3b-aa76-01284215dedd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from data.dataloader import DatasetGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a6d78424-a764-4c1c-960d-d6abbce79cda",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-08 22:30:49.219533: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/ubuntu/miniconda3/envs/optimize_model/lib/python3.7/site-packages/cv2/../../lib64:\n",
      "2022-09-08 22:30:49.219561: W tensorflow/stream_executor/cuda/cuda_driver.cc:326] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2022-09-08 22:30:49.219575: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (ip-10-1-35-172): /proc/driver/nvidia/version does not exist\n",
      "2022-09-08 22:30:49.219844: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "brats_datafiles = DatasetGenerator(data_path=DATA_PATH, \n",
    "                                   train_test_split=TRAIN_TEST_SPLIT,\n",
    "                                   validate_test_split=VALIDATE_TEST_SPLIT,\n",
    "                                   batch_size_train=BATCH_SIZE_TRAIN,\n",
    "                                   batch_size_validate=BATCH_SIZE_VALIDATE,\n",
    "                                   batch_size_test=BATCH_SIZE_TEST,\n",
    "                                   tile_height=TILE_HEIGHT, \n",
    "                                   tile_width=TILE_WIDTH, \n",
    "                                   tile_depth=TILE_DEPTH, \n",
    "                                   number_input_channels=NUMBER_INPUT_CHANNELS,\n",
    "                                   number_output_classes=NUMBER_OUTPUT_CLASSES,\n",
    "                                   random_seed=RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c37fc46d-4e64-4048-a97b-a97327f47b0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDataLoader(DataLoader):\n",
    "\n",
    "    def __init__(self, config):\n",
    "\n",
    "        super().__init__(config)\n",
    "\n",
    "        \"\"\"\n",
    "        You can define this data loader to work with your custom dataset.\n",
    "        In our case, we've already defined a TensorFlow `tf.data` object.\n",
    "        We'll just pass that to the API's data loader and transpose the images and masks\n",
    "        (OpenVINO assumes the data is channels first-- NCHWD)\n",
    "        \"\"\"\n",
    "\n",
    "        self.items = np.arange(config[\"num_samples\"])  # Just pass in how many samples you want to take\n",
    "        self.dataset = config[\"test_dataset\"]\n",
    "\n",
    "        print(\"\\nQuantizing FP32 OpenVINO model to INT8\\n\")\n",
    "\n",
    "        print(f\"Taking {len(self.items):,} random samples from the test dataset\")\n",
    "\n",
    "        self.batch_size = 1\n",
    "\n",
    "    def set_subset(self, indices):\n",
    "        self._subset = None\n",
    "\n",
    "    @property\n",
    "    def batch_num(self):\n",
    "        return ceil(self.size / self.batch_size)\n",
    "\n",
    "    @property\n",
    "    def size(self):\n",
    "        return self.items.shape[0]\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.size\n",
    "\n",
    "    def __getitem__(self, item):\n",
    "        \"\"\"\n",
    "        \"\"\"\n",
    "        ds = self.dataset.take(1).as_numpy_iterator()  # Grab the next batch and take a single element (image/mask)\n",
    "        for img, msk in ds:\n",
    "            img = np.transpose(img, [0,4,1,2,3])  # OpenVINO expects the input to be channels first (NCHWD)\n",
    "            msk = np.transpose(msk, [0,4,1,2,3])  # OpenVINO expects the label/output to be channels first (NCHWD)\n",
    "        \n",
    "        return (item, msk), img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "959fae63-0782-4107-af18-9b2b5ffbef76",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyMetric(Metric):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.name = \"custom Metric - Dice score\"\n",
    "        self._values = []\n",
    "        self.round = 1\n",
    "\n",
    "    @property\n",
    "    def value(self):\n",
    "        \"\"\" Returns accuracy metric value for the last model output. \"\"\"\n",
    "        return {self.name: [self._values[-1]]}\n",
    "\n",
    "    @property\n",
    "    def avg_value(self):\n",
    "        \"\"\" Returns accuracy metric value for all model outputs. \"\"\"\n",
    "        value = np.ravel(self._values).mean()\n",
    "        print(\"Round #{}    Mean {} = {}\".format(self.round, self.name, value))\n",
    "\n",
    "        self.round += 1\n",
    "\n",
    "        return {self.name: value}\n",
    "\n",
    "    def update(self, outputs, labels):\n",
    "        \"\"\" Updates prediction matches.\n",
    "        Args:\n",
    "            outputs: model output\n",
    "            labels: annotations\n",
    "        Put your post-processing code here.\n",
    "        Put your custom metric code here.\n",
    "        The metric gets appended to the list of metric values\n",
    "        \"\"\"\n",
    "\n",
    "        def dice_score(pred, truth):\n",
    "            \"\"\"\n",
    "            Sorensen Dice score\n",
    "            Measure of the overlap between the prediction and ground truth masks\n",
    "            \"\"\"\n",
    "            numerator = np.sum(np.round(pred) * truth) * 2.0\n",
    "            denominator = np.sum(np.round(pred)) + np.sum(truth)\n",
    "\n",
    "            return numerator / denominator\n",
    "\n",
    "\n",
    "        metric = dice_score(labels[0], outputs[0])\n",
    "        self._values.append(metric)\n",
    "\n",
    "    def reset(self):\n",
    "        \"\"\" Resets collected matches \"\"\"\n",
    "        self._values = []\n",
    "\n",
    "    @property\n",
    "    def higher_better(self):\n",
    "        \"\"\"Attribute whether the metric should be increased\"\"\"\n",
    "        return True\n",
    "\n",
    "    def get_attributes(self):\n",
    "        return {self.name: {\"direction\": \"higher-better\", \"type\": \"\"}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b85e5d26-c164-4c16-a79b-0d7857e961e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "maximum_metric_drop = 0.05  # For accuracy-aware training. this defines how much the metric is allowed to change.\n",
    "accuracy_aware_quantization=True\n",
    "\n",
    "\n",
    "dataset_config = {\n",
    "    \"num_samples\": 40,   # Get 40 samples\n",
    "    \"test_dataset\": brats_datafiles.get_test()   # Pass our TensorFlow data loader to the API\n",
    "}\n",
    "\n",
    "# Model config specifies the model name and paths to model .xml and .bin file\n",
    "model_config = Dict(\n",
    "    {\n",
    "        \"model_name\": pot_int8_ir_name,\n",
    "        \"model\": path_to_xml_file,\n",
    "        \"weights\": path_to_bin_file\n",
    "    }\n",
    ")\n",
    "\n",
    "\n",
    "engine_config = Dict({\n",
    "    \"device\": \"CPU\",\n",
    "    \"stat_requests_number\": 4,\n",
    "    \"eval_requests_number\": 4\n",
    "})\n",
    "\n",
    "default_quantization_algorithm = [\n",
    "    {\n",
    "        \"name\": \"DefaultQuantization\",\n",
    "        \"params\": {\n",
    "            \"target_device\": \"CPU\",\n",
    "            \"preset\": \"performance\",\n",
    "            #\"stat_subset_size\": 10\n",
    "        }\n",
    "    }\n",
    "]\n",
    "\n",
    "accuracy_aware_quantization_algorithm = [\n",
    "    {\n",
    "        \"name\": \"AccuracyAwareQuantization\", # compression algorithm name\n",
    "        \"params\": {\n",
    "            \"target_device\": \"CPU\",\n",
    "            \"preset\": \"performance\",\n",
    "            \"stat_subset_size\": 10,\n",
    "            \"metric_subset_ratio\": 0.5, # A part of the validation set that is used to compare full-precision and quantized models\n",
    "            \"ranking_subset_size\": 300, # A size of a subset which is used to rank layers by their contribution to the accuracy drop\n",
    "            \"max_iter_num\": 10,    # Maximum number of iterations of the algorithm (maximum of layers that may be reverted back to full-precision)\n",
    "            \"maximal_drop\": maximum_metric_drop,      # Maximum metric drop which has to be achieved after the quantization\n",
    "            \"drop_type\": \"absolute\",    # Drop type of the accuracy metric: relative or absolute (default)\n",
    "            \"use_prev_if_drop_increase\": True,     # Whether to use NN snapshot from the previous algorithm iteration in case if drop increases\n",
    "            \"base_algorithm\": \"DefaultQuantization\" # Base algorithm that is used to quantize model at the beginning\n",
    "        }\n",
    "    }\n",
    "]\n",
    "\n",
    "class GraphAttrs(object):\n",
    "    def __init__(self):\n",
    "        self.keep_quantize_ops_in_IR = True\n",
    "        self.keep_shape_ops = False\n",
    "        self.data_type = \"FP32\"\n",
    "        self.progress = False\n",
    "        self.generate_experimental_IR_V10 = True\n",
    "        self.blobs_as_inputs = True\n",
    "        self.generate_deprecated_IR_V7 = False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "98048c4d-edc1-49c8-a925-a19fd9edb52f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Quantizing FP32 OpenVINO model to INT8\n",
      "\n",
      "Taking 40 random samples from the test dataset\n",
      "Accuracy-aware quantization method\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-08 22:30:57.195466: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:176] None of the MLIR Optimization Passes are enabled (registered 2)\n",
      "2022-09-08 22:30:57.213032: I tensorflow/core/platform/profile_utils/cpu_utils.cc:114] CPU Frequency: 2899975000 Hz\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_74701/1199068510.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m \u001b[0mmetric_results_FP32\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpipeline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0mcompressed_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpipeline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/optimize_model/lib/python3.7/site-packages/openvino/tools/pot/pipeline/pipeline.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(self, model)\u001b[0m\n\u001b[1;32m     75\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m         \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Evaluation of generated model'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 77\u001b[0;31m         \u001b[0mmetrics\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprint_progress\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprogress_bar_disabled\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     78\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/optimize_model/lib/python3.7/site-packages/openvino/tools/pot/engines/ie_engine.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, stats_layout, sampler, stat_aliases, metric_per_sample, print_progress)\u001b[0m\n\u001b[1;32m    120\u001b[0m                       \u001b[0msampler\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msampler\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m                       \u001b[0mprint_progress\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprint_progress\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 122\u001b[0;31m                       need_metrics_per_sample=metric_per_sample)\n\u001b[0m\u001b[1;32m    123\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m         \u001b[0;31m# Process accumulated statistics\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/optimize_model/lib/python3.7/site-packages/openvino/tools/pot/engines/ie_engine.py\u001b[0m in \u001b[0;36m_predict\u001b[0;34m(self, stats_layout, sampler, print_progress, need_metrics_per_sample)\u001b[0m\n\u001b[1;32m    176\u001b[0m                                         \u001b[0mprint_progress\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprint_progress\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m                                         \u001b[0mneed_metrics_per_sample\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mneed_metrics_per_sample\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 178\u001b[0;31m                                         requests_num=requests_number)\n\u001b[0m\u001b[1;32m    179\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    180\u001b[0m     def _process_infer_output(self, stats_layout, predictions,\n",
      "\u001b[0;32m~/miniconda3/envs/optimize_model/lib/python3.7/site-packages/openvino/tools/pot/engines/ie_engine.py\u001b[0m in \u001b[0;36m_process_dataset_async\u001b[0;34m(self, stats_layout, sampler, print_progress, need_metrics_per_sample, requests_num)\u001b[0m\n\u001b[1;32m    351\u001b[0m         \u001b[0mstart_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    352\u001b[0m         \u001b[0minfer_queue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_callback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcompletion_callback\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 353\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mbatch_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_batch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msampler_iter\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    354\u001b[0m             \u001b[0mbatch_annotations\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimage_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_meta\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_process_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    355\u001b[0m             \u001b[0muser_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mstart_time\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_annotations\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_meta\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/optimize_model/lib/python3.7/site-packages/openvino/tools/pot/samplers/batch_sampler.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_subset_indices\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m             \u001b[0mbatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data_loader\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m                 \u001b[0;32myield\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_74701/2274856350.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, item)\u001b[0m\n\u001b[1;32m     39\u001b[0m         \"\"\"\n\u001b[1;32m     40\u001b[0m         \u001b[0mds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_numpy_iterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Grab the next batch and take a single element (image/mask)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmsk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mds\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m             \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# OpenVINO expects the input to be channels first (NCHWD)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m             \u001b[0mmsk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# OpenVINO expects the label/output to be channels first (NCHWD)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/optimize_model/lib/python3.7/site-packages/tensorflow/python/data/ops/dataset_ops.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   4192\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4193\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4194\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_structure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mto_numpy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4195\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4196\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/optimize_model/lib/python3.7/site-packages/tensorflow/python/data/ops/iterator_ops.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    759\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m__next__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    760\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 761\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_internal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    762\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOutOfRangeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    763\u001b[0m       \u001b[0;32mraise\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/optimize_model/lib/python3.7/site-packages/tensorflow/python/data/ops/iterator_ops.py\u001b[0m in \u001b[0;36m_next_internal\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    745\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterator_resource\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    746\u001b[0m           \u001b[0moutput_types\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_flat_output_types\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 747\u001b[0;31m           output_shapes=self._flat_output_shapes)\n\u001b[0m\u001b[1;32m    748\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    749\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/optimize_model/lib/python3.7/site-packages/tensorflow/python/ops/gen_dataset_ops.py\u001b[0m in \u001b[0;36miterator_get_next\u001b[0;34m(iterator, output_types, output_shapes, name)\u001b[0m\n\u001b[1;32m   2723\u001b[0m       _result = pywrap_tfe.TFE_Py_FastPathExecute(\n\u001b[1;32m   2724\u001b[0m         \u001b[0m_ctx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"IteratorGetNext\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"output_types\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_types\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2725\u001b[0;31m         \"output_shapes\", output_shapes)\n\u001b[0m\u001b[1;32m   2726\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0m_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2727\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model = load_model(model_config=model_config)\n",
    "\n",
    "data_loader = MyDataLoader(dataset_config)\n",
    "\n",
    "metric = MyMetric()\n",
    "\n",
    "\n",
    "engine = IEEngine(config=engine_config, \n",
    "                  data_loader=data_loader, \n",
    "                  metric=metric)\n",
    "\n",
    "if accuracy_aware_quantization:\n",
    "    # https://docs.openvinotoolkit.org/latest/_compression_algorithms_quantization_accuracy_aware_README.html\n",
    "    print(\"Accuracy-aware quantization method\")\n",
    "    pipeline = create_pipeline(accuracy_aware_quantization_algorithm, engine)\n",
    "else:\n",
    "    print(\"Default quantization method\")\n",
    "    pipeline = create_pipeline(default_quantization_algorithm, engine)\n",
    "\n",
    "\n",
    "metric_results_FP32 = pipeline.evaluate(model)\n",
    "\n",
    "compressed_model = pipeline.run(model=model)\n",
    "#compress_model_weights(compressed_model)\n",
    "\n",
    "save_model(model=compressed_model, \n",
    "           save_path=pot_int8_ir_path)\n",
    "\n",
    "metric_results_INT8 = pipeline.evaluate(compressed_model)\n",
    "\n",
    "\n",
    "print(\"\\nFINAL RESULTS\")\n",
    "\n",
    "# print metric value\n",
    "if metric_results_FP32:\n",
    "    for name, value in metric_results_FP32.items():\n",
    "        print(f\"{name: <27s} FP32: {value}\")\n",
    "\n",
    "if metric_results_INT8:\n",
    "    for name, value in metric_results_INT8.items():\n",
    "        print(f\"{name: <27s} INT8: {value}\")\n",
    "\n",
    "\n",
    "print(f\"\\nThe INT8 version of the model has been saved to the directory {pot_int8_ir_path}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01d4cd40-3dfd-4855-9553-3099063ae995",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fb4589c-892d-4cf3-8343-fc21c9fa43a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "ie = Core()\n",
    "model = ie.read_model(model=path_to_xml_file, weights=path_to_bin_file)\n",
    "compiled_model = ie.compile_model(model=model, device_name=\"CPU\")\n",
    "\n",
    "del model\n",
    "\n",
    "input_layer_name = next(iter(compiled_model.inputs))\n",
    "output_layer_name = next(iter(compiled_model.outputs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09262cc9-383d-46da-9df3-b51481628f22",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4ac532d-9837-4b92-be9a-3d74a6e661f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "openvino_filename_int8 = os.path.join(int8_directory, openvino_modelname)\n",
    "path_to_xml_file_int8 = f\"{openvino_filename_int8}.xml\"\n",
    "path_to_bin_file_int8 = f\"{openvino_filename_int8}.bin\"\n",
    "\n",
    "ie_int8 = Core()\n",
    "model_int8 = ie.read_model(model=path_to_xml_file_int8, weights=path_to_bin_file_int8)\n",
    "compiled_model_int8 = ie.compile_model(model=model_int8, device_name=\"CPU\")\n",
    "\n",
    "del model_int8\n",
    "\n",
    "input_layer_name_int8 = next(iter(compiled_model_int8.inputs))\n",
    "output_layer_name_int8 = next(iter(compiled_model_int8.outputs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c5b36a0-7414-4aa6-8221-0dcd7f0035af",
   "metadata": {},
   "outputs": [],
   "source": [
    "from model import dice_coef, soft_dice_coef, dice_loss\n",
    "tf_model = tf.keras.models.load_model(\"/home/ubuntu/unet/3D/3d_unet_decathlon/3d_unet_decathlon.h5\", \n",
    "                                      compile=True, \n",
    "                                      custom_objects={\"dice_coef\":dice_coef, \"soft_dice_coef\":soft_dice_coef, \"dice_loss\":dice_loss})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfb5fc19-156d-4f44-86a3-95185f5a456e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_predictions(img_batch, msk_batch):\n",
    "    for i in range(img_batch.shape[0]):\n",
    "        img = img_batch[i:i+1,:,:,:,:]\n",
    "        msk = msk_batch[i:i+1,:,:,:,:]    \n",
    "    \n",
    "        slicenum=np.argmax(np.sum(msk, axis=(1,2)))  # Find the slice with the largest tumor section\n",
    "\n",
    "        plt.figure(figsize=(20,20))\n",
    "\n",
    "        plt.subplot(1,5,1)\n",
    "        plt.title(\"MRI\", fontsize=20)\n",
    "        plt.imshow(img[0,:,:,slicenum,0], cmap=\"gray\")\n",
    "        plt.subplot(1,5,2)\n",
    "        plt.imshow(msk[0,:,:,slicenum,0], cmap=\"gray\")\n",
    "        plt.title(\"Ground truth\", fontsize=20)\n",
    "\n",
    "        \n",
    "        \"\"\"\n",
    "        TensorFlow Model Prediction\n",
    "        \"\"\"\n",
    "        start_time = time.time()\n",
    "        prediction_tf = tf_model.predict(img)\n",
    "        inference_time_tf = 1000.0*(time.time()-start_time)\n",
    "        prediction_tf = tf.round(prediction_tf)\n",
    "        dice_coef_tf = dice_coef(msk,prediction_tf)\n",
    "\n",
    "        plt.subplot(1,5,3)\n",
    "        plt.imshow(prediction_tf[0,:,:,slicenum,0], cmap=\"gray\")\n",
    "        plt.title(f\"TensorFlow Prediction\\nFP32\\nDice = {dice_coef_tf:.4f}\\n\\nInference time\\n{inference_time_tf:.4f} msecs\", fontsize=20)\n",
    "\n",
    "        \n",
    "        \n",
    "        \"\"\"\n",
    "        OpenVINO Model Prediction - FP32\n",
    "        Note: OpenVINO assumes the input (and output) are organized as channels first (NCHWD)\n",
    "        whereas TensorFlow assumes channels last (NHWDC). We'll use the NumPy transpose\n",
    "        to change the order.\n",
    "        \"\"\"\n",
    "        start_time = time.time()\n",
    "        request = compiled_model.create_infer_request()\n",
    "        request.infer(inputs={input_layer_name.any_name: img})\n",
    "        prediction_ov = request.get_output_tensor(output_layer_name.index).data\n",
    "        inference_time_ov = 1000.0*(time.time()-start_time)\n",
    "        prediction_ov = tf.round(prediction_ov)\n",
    "        dice_coef_ov = dice_coef(msk,prediction_ov)\n",
    "\n",
    "        plt.subplot(1,5,4)\n",
    "        plt.imshow(prediction_ov[0,:,:,slicenum,0], cmap=\"gray\")\n",
    "        plt.title(f\"OpenVINO Prediction\\nFP32\\nDice = {dice_coef_ov:.4f}\\n\\nInference time\\n{inference_time_ov:.4f} msecs\", fontsize=20)\n",
    "\n",
    "        \n",
    "        \"\"\"\n",
    "        OpenVINO Model Prediction - INT8\n",
    "        Note: OpenVINO assumes the input (and output) are organized as channels first (NCHWD)\n",
    "        whereas TensorFlow assumes channels last (NHWDC). We'll use the NumPy transpose\n",
    "        to change the order.\n",
    "        \"\"\"\n",
    "        start_time = time.time()\n",
    "        request_int8 = compiled_model_int8.create_infer_request()\n",
    "        request_int8.infer(inputs={input_layer_name_int8.any_name: img})\n",
    "        prediction_ov_int8 = request_int8.get_output_tensor(output_layer_name_int8.index).data\n",
    "        inference_time_ov_int8 = 1000.0*(time.time()-start_time)\n",
    "        prediction_ov_int8 = tf.round(prediction_ov_int8)\n",
    "        dice_coef_ov_int8 = dice_coef(msk,prediction_ov_int8)\n",
    "\n",
    "        plt.subplot(1,5,5)\n",
    "        plt.imshow(prediction_ov_int8[0,:,:,slicenum,0], cmap=\"gray\")\n",
    "        plt.title(f\"OpenVINO Prediction\\nINT8\\nDice = {dice_coef_ov_int8:.4f}\\n\\nInference time\\n{inference_time_ov_int8:.4f} msecs\", fontsize=20)\n",
    "\n",
    "\n",
    "        \n",
    "        import pickle\n",
    "\n",
    "        data = {'img': img, \n",
    "                'msk': msk, \n",
    "                'prediction_ov_int8': prediction_ov_int8, \n",
    "                'dice_coef_ov_int8': dice_coef_ov_int8,\n",
    "                'inference_time_ov_int8': inference_time_ov_int8,\n",
    "                'prediction_ov': prediction_ov, \n",
    "                'dice_coef_ov': dice_coef_ov,\n",
    "                'inference_time_ov': inference_time_ov,\n",
    "                'prediction_tf': prediction_tf, \n",
    "                'dice_coef_tf': dice_coef_tf,\n",
    "                'inference_time_tf': inference_time_tf\n",
    "               }\n",
    "\n",
    "        # data = [img, msk, prediction_ov, dice_coef_ov, prediction_tf, dice_coef_tf]\n",
    "\n",
    "        with open('/home/ubuntu/unet/data/prediction_results.pkl', 'wb') as outfile:\n",
    "            pickle.dump(data, outfile, pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "        # with open('mat.pkl', 'rb') as infile:\n",
    "        #     result = pickle.load(infile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3638bf7b-f6ca-4e39-80e1-f95f293a049f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "ds = brats_datafiles.get_train().take(1).as_numpy_iterator()\n",
    "for img, msk in ds:\n",
    "    plot_predictions(img,msk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f86daa2-16e1-49e5-9c74-7020081bc11a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "optimize_model",
   "language": "python",
   "name": "optimize_model"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
